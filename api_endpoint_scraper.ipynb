{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# College Tour Information Scraper\n",
    "\n",
    "Gathers information from the https://www.youvisit.com/collegesearch/ website\n",
    "\n",
    "Contact:\n",
    "Ethan Haque (ethanhaque@princeton.edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import random\n",
    "import queue\n",
    "import pandas as pd\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from math import ceil\n",
    "from time import sleep\n",
    "\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering All Institution Ids\n",
    "\n",
    "We can get the ids for each school by exploting open api endpoints. These ids give us part of what we need to get the information contained in the tours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://search.youvisit.com/institution-profiles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of a bunch of user agents to cycle through\n",
    "user_agents = user_agents = open('./data/user_agents.txt').read().splitlines() \n",
    "user_agent = random.choice(user_agents)\n",
    "\n",
    "# can use this to automatically set total records\n",
    "response = requests.get(link, headers={'User-Agent': user_agent}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this may change but hard coding it and changing in the future is easy\n",
    "TOTAL_RECORDS = 8271 \n",
    "RECORDS_PER_PAGE = 100\n",
    "TOTAL_PAGES = ceil(TOTAL_RECORDS / RECORDS_PER_PAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_insitution_data(page_no):\n",
    "    \"\"\"Grabbing important instituion data\"\"\"\n",
    "    data = []\n",
    "    user_agent = random.choice(user_agents)\n",
    "    institution_profiles = requests.get(\"{}?size={}&page={}\".format(link, RECORDS_PER_PAGE, page_no), \n",
    "                                        headers={'User-Agent': user_agent})\n",
    "    json_data = json.loads(institution_profiles.text)\n",
    "    for record in json_data[\"data\"][\"records\"]:\n",
    "        if record[\"has_virtual_tour\"]:\n",
    "            institution_id = record[\"inst_id\"]\n",
    "            institution_name = record[\"name\"]\n",
    "            institution_url = record[\"url\"]\n",
    "            data.append([institution_id, institution_name, institution_url])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all the institution ids along with some other useful information\n",
    "results = queue.Queue()\n",
    "with (tqdm(range(TOTAL_PAGES))) as pbar:\n",
    "    with ThreadPoolExecutor(max_workers=16) as executor:\n",
    "        for data in executor.map(get_insitution_data, range(TOTAL_PAGES)):\n",
    "            for institution in data:\n",
    "                results.put(institution)\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_results = []\n",
    "while not results.empty():\n",
    "    combined_results.append(results.get())\n",
    "institution_dataframe = pd.DataFrame(combined_results, columns = [\"institution-id\", \"institution-name\", \"institution-url\"])\n",
    "institution_dataframe.to_csv(\"./data/inst_ids.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering Tour Ids\n",
    "\n",
    "Using the previously gathered institution ids, we can exploit another open api endpoint to get the tour ids for each individual location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_link = \"https://api.youvisit.com/v1.2/institutions/{}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_institution_tour_location_info(institution_id, institution_name):\n",
    "    \"\"\"Grabs info from api endpoint related to an institution, which contains tour ids.\"\"\"\n",
    "    data = []\n",
    "    user_agent = random.choice(user_agents)\n",
    "    tour_info = requests.get(locations_link.format(institution_id), headers={'User-Agent': user_agent})\n",
    "    json_data = json.loads(tour_info.text)\n",
    "    if json_data[\"data\"]:\n",
    "        for locaiton in json_data[\"data\"][0][\"locations\"]:\n",
    "            location_id = locaiton[\"loc_id\"]\n",
    "            data.append([institution_id, institution_name, location_id])\n",
    "    return data \n",
    "    \n",
    "def tour_location_ids_helper(row):\n",
    "    \"\"\"Takes in a dataframe row and calls proper methods\"\"\"\n",
    "    return grab_institution_tour_location_info(row[\"institution-id\"], row[\"institution-name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# getting all the institution ids along with some other useful information\n",
    "results = queue.Queue()\n",
    "with (tqdm(range(institution_dataframe.shape[0]))) as pbar:\n",
    "    with ThreadPoolExecutor(max_workers=16) as executor:\n",
    "        for data in executor.map(tour_location_ids_helper, [row for index, row in institution_dataframe.iterrows()]):\n",
    "            if data:\n",
    "                for institution in data:\n",
    "                    results.put(institution)\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_results = []\n",
    "while not results.empty():\n",
    "    combined_results.append(results.get())\n",
    "location_dataframe = pd.DataFrame(combined_results, columns = [\"institution-id\", \"institution-name\", \"location-id\"])\n",
    "location_dataframe.to_csv(\"./data/location_ids.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering Stops on Tours\n",
    "\n",
    "By tweaking the earlier api call we can get out the stops information from the webserver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tour_data_link = \"https://api.youvisit.com/v1.2/institutions/{}/locations/{}/stops?expand=all&allowInProgress=locations,tours&limit=1000&env=www\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json_response(output_path, info):\n",
    "    \"\"\"Saves content to a file.\"\"\"\n",
    "    with open(output_path, 'w') as outf:\n",
    "        json.dump(info, outf)\n",
    "        \n",
    "def grab_tour_info(institution_id, tour_id):\n",
    "    \"\"\"\n",
    "    Grabs info from api endpoint containing information related to the stops on a tour with the corresponding\n",
    "    content for the media on the tour.\n",
    "    \"\"\"\n",
    "    user_agent = random.choice(user_agents)\n",
    "    tour_info = requests.get(tour_data_link.format(institution_id, tour_id), headers={'User-Agent': user_agent})\n",
    "    json_data = json.loads(tour_info.text)\n",
    "    return json_data\n",
    "\n",
    "def save_tour_info(institution_id, tour_id, institution_name):\n",
    "    \"\"\"Saves json response for tour info.\"\"\"\n",
    "    info = grab_tour_info(institution_id, tour_id)\n",
    "    output_folder = \"./data/tour_media_info\"\n",
    "    output_file_path = \"{}/{}-{}-{}.json\".format(output_folder, institution_name, institution_id, tour_id)\n",
    "    save_json_response(output_file_path, info)\n",
    "    \n",
    "def save_tour_info_helper(row):\n",
    "    \"\"\"Helper for the save_tour_info method\"\"\"\n",
    "    save_tour_info(row[\"institution-id\"], row[\"location-id\"], row[\"institution-name\"])\n",
    "\n",
    "def grab_media_from_stop(stop):\n",
    "    \"\"\"Grabs the array of photos and panoramas from a stop.\"\"\"\n",
    "    return stop[\"photos\"], stop[\"panoramas\"]\n",
    "\n",
    "def get_important_media(institution_id, institution_name, tour_id, title, item, media_type):\n",
    "    \"\"\"Gets important information from panos and photos.\"\"\"\n",
    "    return [\n",
    "        institution_id,\n",
    "        institution_name,\n",
    "        tour_id,\n",
    "        title,\n",
    "        item[\"id\"],\n",
    "        item[\"title\"],\n",
    "        item[\"description\"],\n",
    "        media_type\n",
    "    ]\n",
    "\n",
    "def gather_media_from_tour_info(institution_id, tour_id, institution_name):\n",
    "    \"\"\"Creates an array of data for each tour and saves the requested data to create a backup.\"\"\"\n",
    "    info = grab_tour_info(institution_id, tour_id)\n",
    "    stops = info[\"data\"]\n",
    "    data = []\n",
    "    if stops:\n",
    "        for stop in stops:\n",
    "            photos, panos = grab_media_from_stop(stop)\n",
    "            title = stop[\"title\"]\n",
    "            for photo in photos:\n",
    "                important_data = get_important_media(institution_id, institution_name, tour_id, title, photo, \"photo\")\n",
    "                data.append(important_data)\n",
    "                \n",
    "            for pano in panos:\n",
    "                important_data = get_important_media(institution_id, institution_name, tour_id, title, pano, \"pano\")\n",
    "                data.append(important_data)\n",
    "            \n",
    "            \n",
    "    save_tour_info(institution_id, tour_id, institution_name)\n",
    "    return data\n",
    "\n",
    "def gather_media_from_tour_info_helper(row):\n",
    "    \"\"\"\n",
    "    Helper method for gather_media_from_tour_info that wraps the function call allowing a row in the df\n",
    "    to be the input.\n",
    "    \"\"\"\n",
    "    return gather_media_from_tour_info(row[\"institution-id\"], row[\"location-id\"], row[\"institution-name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = queue.Queue()\n",
    "with (tqdm(range(location_dataframe.shape[0]))) as pbar:\n",
    "    with ThreadPoolExecutor(max_workers=16) as executor:\n",
    "        for data in executor.map(gather_media_from_tour_info_helper, [row for index, row in location_dataframe.iterrows()]):\n",
    "            if data:\n",
    "                for media_item in data:\n",
    "                    results.put(media_item)\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_results = []\n",
    "while not results.empty():\n",
    "    combined_results.append(results.get())\n",
    "    \n",
    "media_dataframe = pd.DataFrame(combined_results, columns = [\n",
    "    \"institution_id\", \n",
    "    \"institution_name\", \n",
    "    \"tour_id\",\n",
    "    \"stop_title\",\n",
    "    \"media_id\",\n",
    "    \"media_title\",\n",
    "    \"media_description\",\n",
    "    \"media_type\"\n",
    "])\n",
    "\n",
    "media_dataframe.to_csv(\"./data/media_info.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading All Unique Content\n",
    "\n",
    "Downloads all the photos and panoramas served on the website for each tour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lots of media are used multiple times in the same tour so drop duplicate media_id's\n",
    "# Description and other data points might be different, but that does not matter.\n",
    "# Those pieces of data can be cross-referenced later.\n",
    "unique_media = media_dataframe.drop_duplicates(subset=['media_id'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youvisit.com/media/LOC_ID/MEDIA_TYPE/ID/SIZE\n",
    "media_url = \"https://www.youvisit.com/media/{}/{}/{}/{}.jpg\"\n",
    "output_dir = \"./data/all_media\"\n",
    "size = \"2048\"\n",
    "media_types = {\n",
    "    \"photo\": \"photos\",\n",
    "    \"pano\": \"panoramas\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_media(output_path, media):\n",
    "    \"\"\"Saves images to path.\"\"\"\n",
    "    with open(output_path, 'wb') as handler:\n",
    "        handler.write(media)\n",
    "        \n",
    "def grab_media(location_id, media_type, media_id, size):\n",
    "    \"\"\"Grabs media from url.\"\"\"\n",
    "    url = media_url.format(location_id, media_type, media_id, size)\n",
    "    media = requests.get(url).content\n",
    "    return media\n",
    "\n",
    "def grab_and_save_media(row):\n",
    "    \"\"\"Saves media from info in row of dataframe.\"\"\"\n",
    "    location_id = row[\"tour_id\"]\n",
    "    media_type = media_types[row[\"media_type\"]]\n",
    "    media_id = row[\"media_id\"]\n",
    "    media = grab_media(location_id, media_type, media_id, size)\n",
    "    \n",
    "    output_path = \"{}/{}.jpg\".format(output_dir, media_id)\n",
    "    save_media(output_path, media)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all the media and saving them\n",
    "with (tqdm(range(unique_media.shape[0]))) as pbar:\n",
    "    with ThreadPoolExecutor(max_workers=16) as executor:\n",
    "        for data in executor.map(grab_and_save_media, [row for index, row in unique_media.iterrows()]):\n",
    "            pbar.update(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:web-scraping]",
   "language": "python",
   "name": "conda-env-web-scraping-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
